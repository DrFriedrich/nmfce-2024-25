{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9357af5-16bf-49dc-945c-b70582eb2059",
   "metadata": {},
   "source": [
    "# W10-W3: Gradient based optimisation\n",
    "\n",
    "This notebook covers the gradient based optimisation solvers Steepest descent, Conjugate gradient and Newton's method. We will demonstrate and compare them for a 2D problem.\n",
    "\n",
    "---\n",
    "\n",
    "#### Displaying solutions\n",
    "\n",
    "Solutions will be released after the workshop, as a new `.txt` file in the same GitHub repository. After pulling the file to Noteable, **run the following cell** to create clickable buttons under each exercise, which will allow you to reveal the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb57cd7-b33f-463d-be1d-862a7481ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/create_widgets.py W10-W3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69dd98c-9ba3-40a4-b6b4-7450ab2b08ee",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49332904-e319-41c9-b6bf-6f1457a9b2e2",
   "metadata": {},
   "source": [
    "## Part a) \n",
    "\n",
    "Define the function $$f(\\mathbf{x}) = (x_1 + 2x_2 - 7)^2 + (2x_1 + x_2 - 5)^2$$ and its gradient. Plot both of them; see the nonlinear optimisation notebook for an example how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d2674-b36d-4f30-8fde-d0ac6883dcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452d3da-7498-4564-8b62-e3c10c70c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W10-W3_parta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444adf9f-f4b9-482e-a03e-4b142ce6c4b4",
   "metadata": {},
   "source": [
    "## Part b) \n",
    "\n",
    "Implement the Steepest descent solver and solve the problem from part a). For simplicity set the step size as a parameter and test different values between $0$ and $1$. This is clearly not optimal but much easier to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b2ef6-94f0-4635-80a4-51d234fd05dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35587e-b683-40c7-8c38-c92100726574",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W10-W3_partb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24688def-8cc5-46b3-b1c7-10b3e3400f21",
   "metadata": {},
   "source": [
    "## Part c)\n",
    "\n",
    "Plot the function contours and the steps of the steepest descent method towards the true minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb627d-a3fb-4a13-a84f-b731d6c055bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6570eb-78e3-47ab-8ee8-2da26899c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W10-W3_partc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092045cc-e1c2-4a32-abfd-7db6d1a2d326",
   "metadata": {},
   "source": [
    "## Part d)\n",
    "\n",
    "Use the Conjugate Gradient method from the SciPy package to solve the same problem. Use the callback function to store the previous steps and plot them in a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8f8e1-5e29-484b-8eac-8ed4c6ed66c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f47aa0-b8cb-4fba-a1bf-8b62c4f225e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W10-W3_partd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e953be-9321-4674-b12c-e5acb9c14c16",
   "metadata": {},
   "source": [
    "## Part e) \n",
    "\n",
    "Implement the Conjugate Gradient and/or Newton's method yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43f2a9-8e44-4748-964b-03fa454c143b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
